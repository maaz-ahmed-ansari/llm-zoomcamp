{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "666a2c9c-d557-48db-b39c-bd69bfdb3c46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:21:24.210704Z",
     "iopub.status.busy": "2024-09-16T18:21:24.210453Z",
     "iopub.status.idle": "2024-09-16T18:21:25.550631Z",
     "shell.execute_reply": "2024-09-16T18:21:25.549923Z",
     "shell.execute_reply.started": "2024-09-16T18:21:24.210679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-16 18:21:25--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py’\n",
      "\n",
      "minsearch.py        100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-09-16 18:21:25 (50.1 MB/s) - ‘minsearch.py’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!rm -f minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d81f049-3f41-4dde-8c68-7c55cd16ad3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:21:33.778830Z",
     "iopub.status.busy": "2024-09-16T18:21:33.778504Z",
     "iopub.status.idle": "2024-09-16T18:21:33.782498Z",
     "shell.execute_reply": "2024-09-16T18:21:33.781801Z",
     "shell.execute_reply.started": "2024-09-16T18:21:33.778803Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '/run/cache/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c846b77-bd66-4824-94a1-ba1d51dd9a01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:21:51.689353Z",
     "iopub.status.busy": "2024-09-16T18:21:51.689020Z",
     "iopub.status.idle": "2024-09-16T18:21:51.695903Z",
     "shell.execute_reply": "2024-09-16T18:21:51.695237Z",
     "shell.execute_reply.started": "2024-09-16T18:21:51.689329Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/run/cache/'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get('HF_HOME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "689952e9-20fe-45aa-9d22-668a7491c51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:38:55.001964Z",
     "iopub.status.busy": "2024-09-16T13:38:55.001636Z",
     "iopub.status.idle": "2024-09-16T13:38:55.015751Z",
     "shell.execute_reply": "2024-09-16T13:38:55.015249Z",
     "shell.execute_reply.started": "2024-09-16T13:38:55.001940Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import minsearch\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0c8fa8a-b9b8-4f66-94e7-0f4d4a4b909c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:22:55.034164Z",
     "iopub.status.busy": "2024-09-16T18:22:55.033812Z",
     "iopub.status.idle": "2024-09-16T18:22:58.548484Z",
     "shell.execute_reply": "2024-09-16T18:22:58.547831Z",
     "shell.execute_reply.started": "2024-09-16T18:22:55.034139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<minsearch.Index at 0x7ff2b4453110>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests \n",
    "import json\n",
    "import minsearch\n",
    "\n",
    "docs_url = 'https://github.com/DataTalksClub/llm-zoomcamp/blob/main/01-intro/documents.json?raw=1'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)\n",
    "\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")\n",
    "\n",
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c956457-8ad3-4b47-a06b-608d52e9e5b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:23:03.939378Z",
     "iopub.status.busy": "2024-09-16T18:23:03.938922Z",
     "iopub.status.idle": "2024-09-16T18:23:03.943305Z",
     "shell.execute_reply": "2024-09-16T18:23:03.942562Z",
     "shell.execute_reply.started": "2024-09-16T18:23:03.939353Z"
    }
   },
   "outputs": [],
   "source": [
    "def search(query):\n",
    "    boost = {'question': 3.0, 'section': 0.5}\n",
    "\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79738d56-c165-45ca-a5d6-1426b78f4b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:23:05.433170Z",
     "iopub.status.busy": "2024-09-16T18:23:05.432840Z",
     "iopub.status.idle": "2024-09-16T18:23:05.438122Z",
     "shell.execute_reply": "2024-09-16T18:23:05.437423Z",
     "shell.execute_reply.started": "2024-09-16T18:23:05.433145Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT: \n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f29dd5e-14bd-4db4-8cc7-7762dafc93b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:23:06.783214Z",
     "iopub.status.busy": "2024-09-16T18:23:06.782866Z",
     "iopub.status.idle": "2024-09-16T18:23:06.786923Z",
     "shell.execute_reply": "2024-09-16T18:23:06.786198Z",
     "shell.execute_reply.started": "2024-09-16T18:23:06.783192Z"
    }
   },
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = search(query)\n",
    "    prompt = build_prompt(query, search_results)\n",
    "    answer = llm(prompt)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef78910-f483-49e5-84de-5b38f39973b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T13:39:07.598828Z",
     "iopub.status.busy": "2024-09-16T13:39:07.598336Z",
     "iopub.status.idle": "2024-09-16T13:39:09.174622Z",
     "shell.execute_reply": "2024-09-16T13:39:09.173946Z",
     "shell.execute_reply.started": "2024-09-16T13:39:07.598791Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To run Kafka in your project, you can use the following command in the terminal for Java Kafka:\n",
      "\n",
      "```bash\n",
      "java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java\n",
      "```\n",
      "\n",
      "If you are using Python, make sure to create a virtual environment and run the necessary requirements. Here’s how you can do it:\n",
      "\n",
      "1. Create a virtual environment and install required packages:\n",
      "   ```bash\n",
      "   python -m venv env\n",
      "   source env/bin/activate  # For MacOS and Linux\n",
      "   pip install -r ../requirements.txt\n",
      "   ```\n",
      "\n",
      "2. To activate the virtual environment, run:\n",
      "   ```bash\n",
      "   source env/bin/activate  # For MacOS and Linux\n",
      "   ```\n",
      "\n",
      "   For Windows, use:\n",
      "   ```bash\n",
      "   env\\Scripts\\activate\n",
      "   ```\n",
      "\n",
      "3. To deactivate the virtual environment when done, run:\n",
      "   ```bash\n",
      "   deactivate\n",
      "   ```\n",
      "\n",
      "Remember that you need to have Docker images up and running if you are using Docker with Kafka.\n"
     ]
    }
   ],
   "source": [
    "query = 'how do I run Kafka?'\n",
    "answer = rag(query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd33f42-aeca-40f0-849c-e5af065ad666",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8454034d-1f53-4b27-ae5c-657baf73720a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:23:27.210964Z",
     "iopub.status.busy": "2024-09-16T18:23:27.210616Z",
     "iopub.status.idle": "2024-09-16T18:23:33.832154Z",
     "shell.execute_reply": "2024-09-16T18:23:33.831490Z",
     "shell.execute_reply.started": "2024-09-16T18:23:27.210942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7ff26d04d770>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "torch.random.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "785d8f89-065f-43cb-8ce8-9def6af99be2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:23:55.413709Z",
     "iopub.status.busy": "2024-09-16T18:23:55.413212Z",
     "iopub.status.idle": "2024-09-16T18:23:56.049274Z",
     "shell.execute_reply": "2024-09-16T18:23:56.048458Z",
     "shell.execute_reply.started": "2024-09-16T18:23:55.413673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filesystem      Size  Used Avail Use% Mounted on\n",
      "overlay         100G   39G   62G  39% /\n",
      "tmpfs            64M     0   64M   0% /dev\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/fs/cgroup\n",
      "/dev/nvme0n1p1  100G   39G   62G  39% /run\n",
      "tmpfs            14G  4.0K   14G   1% /dev/shm\n",
      "/dev/nvme2n1    2.0G  152M  1.8G   8% /home/jovyan\n",
      "tmpfs            14G  120K   14G   1% /home/jovyan/.saturn\n",
      "tmpfs            14G   12K   14G   1% /run/secrets/kubernetes.io/serviceaccount\n",
      "tmpfs           7.7G   12K  7.7G   1% /proc/driver/nvidia\n",
      "tmpfs           7.7G  3.0M  7.7G   1% /run/nvidia-persistenced/socket\n",
      "tmpfs           7.7G     0  7.7G   0% /proc/acpi\n",
      "tmpfs           7.7G     0  7.7G   0% /sys/firmware\n"
     ]
    }
   ],
   "source": [
    "!df -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3247f055-1927-41ef-9bcd-181d9cea661c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:24:46.562400Z",
     "iopub.status.busy": "2024-09-16T18:24:46.562027Z",
     "iopub.status.idle": "2024-09-16T18:25:50.680390Z",
     "shell.execute_reply": "2024-09-16T18:25:50.679822Z",
     "shell.execute_reply.started": "2024-09-16T18:24:46.562371Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3de9fcc71c476fae5d25dfbb9bb676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/3.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83a729ba956343a4925fdc757e9ca9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "configuration_phi3.py:   0%|          | 0.00/11.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- configuration_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152cad5961aa44678cf48e9e1e75f2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modeling_phi3.py:   0%|          | 0.00/73.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/microsoft/Phi-3-mini-128k-instruct:\n",
      "- modeling_phi3.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n",
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd40129d57742f0971665294355fb15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/16.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4ef3e98f3044cfaa5a0aefd62964c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e1fde470dd453eb9242a1b3c0c61a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f3ee39405246b1aa9b64b227b3ee8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/2.67G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122666e21bc8443082224ad8624ddc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67625fbbada472bb874c6a4da766b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained( \n",
    "    \"microsoft/Phi-3-mini-128k-instruct\",  \n",
    "    device_map=\"cuda\",  \n",
    "    torch_dtype=\"auto\",  \n",
    "    trust_remote_code=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc826ecf-795e-4fff-94bc-ae588a1756c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:26:46.357880Z",
     "iopub.status.busy": "2024-09-16T18:26:46.357526Z",
     "iopub.status.idle": "2024-09-16T18:26:46.962046Z",
     "shell.execute_reply": "2024-09-16T18:26:46.961464Z",
     "shell.execute_reply.started": "2024-09-16T18:26:46.357857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45956aac525e4319beb415cbed2a780f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ad3efdf0e345f8985b52e1e07c2ff0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1250643b347a44088c666de06baa35b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.94M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd99a95a3bb4a38bd864f2e5c64586c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/306 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f65b1ff516cc42d1a3b71c343daffa6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/599 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/Phi-3-mini-128k-instruct\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2e9b129-7a58-4865-a4b7-007ef2cccf31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:27:56.596866Z",
     "iopub.status.busy": "2024-09-16T18:27:56.596503Z",
     "iopub.status.idle": "2024-09-16T18:27:56.600524Z",
     "shell.execute_reply": "2024-09-16T18:27:56.599741Z",
     "shell.execute_reply.started": "2024-09-16T18:27:56.596840Z"
    }
   },
   "outputs": [],
   "source": [
    "pipe = pipeline( \n",
    "    \"text-generation\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03c861e7-d64b-425a-92aa-c3676c7a9c2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:29:29.384129Z",
     "iopub.status.busy": "2024-09-16T18:29:29.383464Z",
     "iopub.status.idle": "2024-09-16T18:29:37.897948Z",
     "shell.execute_reply": "2024-09-16T18:29:37.897174Z",
     "shell.execute_reply.started": "2024-09-16T18:29:29.384088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/saturncloud/envs/saturn/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:567: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n",
      "The `seen_tokens` attribute is deprecated and will be removed in v4.41. Use the `cache_position` model input instead.\n",
      "You are not running the flash-attention implementation, expect numerical differences.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Yes, you can still join the course. Enrollment for courses is typically open until the course is fully enrolled or until a set deadline is reached. To determine if you can still join, you should check the course's enrollment status on the platform you're using, such as Coursera, edX, or the specific university's website. If the course is still accepting new enrollments, you can sign up for it. If it's no longer accepting new students, you may consider looking for similar courses or waiting for the next available term.\n"
     ]
    }
   ],
   "source": [
    "messages = [ \n",
    "    {\"role\": \"system\", \"content\": \"I just discovered the course. Can I still join?\"} \n",
    "]  \n",
    "\n",
    "generation_args = { \n",
    "    \"max_new_tokens\": 500, \n",
    "    \"return_full_text\": False, \n",
    "    \"temperature\": 0.0, \n",
    "    \"do_sample\": False, \n",
    "} \n",
    "\n",
    "output = pipe(messages, **generation_args) \n",
    "print(output[0]['generated_text']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0bc46e8b-42e8-44dc-a862-19043f112598",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:33:14.965381Z",
     "iopub.status.busy": "2024-09-16T18:33:14.965038Z",
     "iopub.status.idle": "2024-09-16T18:33:14.970243Z",
     "shell.execute_reply": "2024-09-16T18:33:14.969524Z",
     "shell.execute_reply.started": "2024-09-16T18:33:14.965359Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "    You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "    Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "    \n",
    "    QUESTION: {question}\n",
    "    \n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "def llm(prompt):\n",
    "    messages = [ \n",
    "        {\"role\": \"system\", \"content\": prompt} \n",
    "    ]  \n",
    "    \n",
    "    generation_args = { \n",
    "        \"max_new_tokens\": 500, \n",
    "        \"return_full_text\": False, \n",
    "        \"temperature\": 0.0, \n",
    "        \"do_sample\": False, \n",
    "    } \n",
    "    \n",
    "    output = pipe(messages, **generation_args) \n",
    "    return output[0]['generated_text'].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "266181f6-37d3-43ea-8207-123580253bd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-16T18:33:15.951415Z",
     "iopub.status.busy": "2024-09-16T18:33:15.951073Z",
     "iopub.status.idle": "2024-09-16T18:33:22.517569Z",
     "shell.execute_reply": "2024-09-16T18:33:22.516906Z",
     "shell.execute_reply.started": "2024-09-16T18:33:15.951392Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You can still join the course even if you discover it after the start date. You are eligible to submit the homeworks, but remember to meet the deadlines for the final projects. The course will start on January 15th, 2024 at 5:00 PM (17:00). You can register before the course starts using the provided link.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag(\"I just discovered the course. Can I still join it?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af81a5b-31f9-406c-be2f-b181d28fc257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
